# -*- coding: utf-8 -*-
"""resnet18.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fvOC1L0TbgEvIFgcrHnYl9A_tr5X-5XB
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torch.backends.cudnn as cudnn
import torchvision
import torchvision.transforms as transforms
import PIL
import numpy as np
import os
import argparse
import matplotlib.pyplot as plt

class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, in_planes, planes, stride=1):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(
            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,
                               stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)

        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != self.expansion*planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, self.expansion*planes,
                          kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(self.expansion*planes)
            )

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        out = F.relu(out)
        return out

class ResNet(nn.Module):
    def __init__(self, block, num_blocks, num_classes=10):
        super(ResNet, self).__init__()
        self.in_planes = 64

        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,
                               stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)
        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)
        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)
        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)
        self.linear = nn.Linear(512*block.expansion, num_classes)

    def _make_layer(self, block, planes, num_blocks, stride):
        strides = [stride] + [1]*(num_blocks-1)
        layers = []
        for stride in strides:
            layers.append(block(self.in_planes, planes, stride))
            self.in_planes = planes * block.expansion
        return nn.Sequential(*layers)

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = F.avg_pool2d(out, 4)
        out = out.view(out.size(0), -1)
        out = self.linear(out)
        return out

def ResNet18():
    return ResNet(BasicBlock, [2, 2, 2, 2])

device = 'cuda' if torch.cuda.is_available() else 'cpu'
best_acc = 0  # best test accuracy
start_epoch = 0  # start from epoch 0 or last checkpoint epoch

# Data
print('==> Preparing data..')
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])

trainset = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True, transform=transform_train)
trainloader = torch.utils.data.DataLoader(
    trainset, batch_size=128, shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(
    root='./data', train=False, download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(
    testset, batch_size=100, shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck')

net = ResNet18()
print(net)

# Model
print('==> Building model..')
net = ResNet18()
net = net.to(device)
if device == 'cuda':
    net = torch.nn.DataParallel(net)
    cudnn.benchmark = True

lr = 0.1
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr,
                      momentum=0.9, weight_decay=5e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)


# Training
def train(epoch):
    print('\nEpoch: %d' % epoch)
    net.train()
    train_loss = 0
    correct = 0
    total = 0
    for batch_idx, (inputs, targets) in enumerate(trainloader):
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()

      

    print('Train Epoch: {} [{}/{} ({:.0f}%)] \tAcc: {:.3f}% ({}/{}) \tLoss: {:.6f}'.format(
              epoch, batch_idx * len(inputs), len(trainloader.dataset), 100. * batch_idx / len(trainloader), 100.*correct/total, correct, total, train_loss/(batch_idx+1)))
    return 100.*correct/total, train_loss/(batch_idx+1)

def test(epoch):
    global best_acc
    net.eval()
    test_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for batch_idx, (inputs, targets) in enumerate(testloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            loss = criterion(outputs, targets)

            test_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

        
      
        print(
            '\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
            test_loss/(batch_idx+1), correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))

    # Save checkpoint.
    acc = 100.*correct/total
    if acc > best_acc:
        print('Saving..')
        state = {
            'net': net.state_dict(),
            'acc': acc,
            'epoch': epoch,
        }
        if not os.path.isdir('checkpoint'):
            os.mkdir('checkpoint')
        torch.save(state, './checkpoint/ckpt.pth')
        best_acc = acc
    return acc, test_loss/(batch_idx+1)

train_acc = []
test_acc = []
train_loss = []
test_loss = []
for epoch in range(0, 50):
    
    acc, loss = train(epoch)
    train_acc.append(acc)
    train_loss.append(loss)
    acc, loss = test(epoch)
    test_acc.append(acc)
    test_loss.append(loss)
    scheduler.step()

from matplotlib.legend_handler import HandlerLine2D
epochs = np.linspace(0, 50, 50, endpoint=True)
line1, = plt.plot(epochs, train_acc, 'b', label='Train Acc')
line2, = plt.plot(epochs, test_acc, 'r', label='Test Acc')
# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
plt.legend()
plt.ylabel('Accuracy')
# plt.xlabel('Epochs')
plt.title('CNN_ResNet18')
plt.show()

from matplotlib.legend_handler import HandlerLine2D
epochs = np.linspace(0, 50, 50, endpoint=True)
line1, = plt.plot(epochs, train_loss, 'b', label='Train Loss')
line2, = plt.plot(epochs, test_loss, 'r', label='Test Loss')
# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
plt.legend()
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.title('CNN_ResNet18')
plt.show()

"""PART A"""

import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import torch.optim as optim
from torch.optim import lr_scheduler
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import numpy as np
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
from torch.utils.data import random_split
from torchvision.transforms import ToTensor
import time
import copy

torch.manual_seed(43)

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])

dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
train_X, val_X = random_split(dataset, [40000, 10000])
test_ds = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

image_datasets = {'train': train_X, 'val': val_X, 'test': test_ds}

batch_size = 128
train_loader = torch.utils.data.DataLoader(train_X, batch_size, shuffle=True, num_workers=4, pin_memory=True)
val_loader = torch.utils.data.DataLoader(val_X, batch_size*2, num_workers=4, pin_memory=True)
test_loader = torch.utils.data.DataLoader(test_ds, batch_size*2, num_workers=4, pin_memory=True)

dataloaders = {'train': train_loader, 'val': val_loader, 'test': test_loader}
dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

def train_model(model, criterion, optimizer, scheduler, ne, ac, ls):
    since = time.time()

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(ne):
        print('Epoch {}/{}'.format(epoch, ne - 1))
        print('-' * 10)

        for phase in ['train', 'val']:
            if phase == 'train':
                model.train() 
            else:
                model.eval()

            loss_run = 0.0
            running_corrects = 0

            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()

                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                loss_run += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
            if phase == 'train':
                scheduler.step()

            loss_epoch = loss_run / dataset_sizes[phase]
            #print(loss_epoch,type(loss_epoch))
            #input()
            ls[phase].append(loss_epoch)
            #print(running_corrects.item())
            epoch_acc = running_corrects.double() / dataset_sizes[phase]
            #print(epoch_acc.item(),type(epoch_acc.item()))
            #input()
            ac[phase].append(epoch_acc.item())

            print('{} Loss: {:.4f} Acc: {:.4f}'.format(
                phase, loss_epoch, epoch_acc))

            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())
            
            #print(ls[phase])
            #print(ac[phase])
            #input()
        print()

    time_elapsed = time.time() - since
    print('Total training time: {:.0f}m {:.0f}s'.format(
        time_elapsed // 60, time_elapsed % 60))
    print('Maximum validation set Acc: {:4f}'.format(best_acc))

    model.load_state_dict(best_model_wts)
    return model

def evaluate(model, phase):
    model.eval()  

    loss_run = 0.0
    running_corrects = 0

    for inputs, labels in dataloaders[phase]:
        inputs = inputs.to(device)
        labels = labels.to(device)

        with torch.set_grad_enabled(phase == 'train'):
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)

        loss_run += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)

    loss_epoch = loss_run / dataset_sizes[phase]
    epoch_acc = running_corrects.double() / dataset_sizes[phase]

    return loss_epoch, epoch_acc

model1 = models.resnet18(pretrained=False)
num1 = model1.fc.in_features
model1.fc = nn.Linear(num1, 10)
model1 = model1.to(device)
criterion = nn.CrossEntropyLoss()
optimizer_rn = optim.Adam(model1.parameters(), lr=0.01)
exp_lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer_rn, T_max=200)

model1

accuracy1 = {'train': [], 'val': []}
loss1 = {'train': [], 'val': []}
num_epochs = 20
model1 = train_model(model1, criterion, optimizer_rn, exp_lr_scheduler, num_epochs, accuracy1, loss1)

accuracy1['train']

accuracy1['val']

fig = plt.figure(figsize=(9,5))
plt.plot(accuracy1['train'], label='train_acc')
plt.plot(accuracy1['val'], label='val_acc')
plt.xlabel('Number of Epochs')
plt.ylabel('Accuracy')
plt.legend()

fig = plt.figure(figsize=(9,5))
plt.plot(loss1['train'], label='train_loss')
plt.plot(loss1['val'], label='val_loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

_, acc_train1 = evaluate(model1, 'train')
_, acc_val1 = evaluate(model1, 'val')
_, acc_test1 = evaluate(model1, 'test')

print('Training  Accuracy:   %.3f' % acc_train1)
print('Validation Accuracy:  %.3f' % acc_val1)
print('Testing Accuracy:     %.3f' % acc_test1)

model2 = models.resnet18(pretrained=True)
num2 = model2.fc.in_features

model2.fc = nn.Linear(num2, 10)

model2 = model2.to(device)
criterion = nn.CrossEntropyLoss()
optimizer_ft = optim.Adam(model2.parameters(), lr=0.001)
exp_lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=200)

model2

acc2 = {'train': [], 'val': []}
loss2 = {'train': [], 'val': []}
num_epochs = 30
model2 = train_model(model2, criterion, optimizer_ft, exp_lr_scheduler, num_epochs, acc2, loss2)

fig = plt.figure(figsize=(9,5))
plt.plot(acc2['train'], label='train_acc')
plt.plot(acc2['val'], label='val_acc')
plt.xlabel('Number of Epochs')
plt.ylabel('Accuracy')
plt.legend()

fig = plt.figure(figsize=(9,5))
plt.plot(loss2['train'], label='train_loss')
plt.plot(loss2['val'], label='val_loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

_, train_acc_ft = evaluate(model2, 'train')
_, val_acc_ft = evaluate(model2, 'val')
_, test_acc_ft = evaluate(model2, 'test')

print('Training  Accuracy:   %.3f' % train_acc_ft)
print('Validation Accuracy:  %.3f' % val_acc_ft)
print('Testing Accuracy:     %.3f' % test_acc_ft)

fig = plt.figure(figsize=(9,5))
plt.plot(accuracy1['train'], 'b', label='pretrained = false')
plt.plot(acc2['train'], 'g',label='pretrained = true')
plt.xlabel('Epochs')
plt.ylabel('Training Accuracy')
plt.title('Comparison between base model and pretrained model with traininable weights')
plt.legend()

fig = plt.figure(figsize=(9,5))
plt.plot(loss1['train'], 'b', label='pretrained = false')
plt.plot(loss2['train'], 'g',label='pretrained = true')
plt.xlabel('Epochs')
plt.ylabel('Training Loss')
plt.title('Comparison between base model and pretrained model with traininable weights')
plt.legend()

model3 = torchvision.models.resnet18(pretrained=True)


ct = 0
index = 0
for name, child in model3.named_children():
    index += 1
    if index < 7:
        for name2, params in child.named_parameters():
            params.requires_grad = False

num2 = model3.fc.in_features

model3.fc = nn.Sequential(
    nn.Linear(num2, 256), nn.ReLU(), nn.Dropout(0.2),
    nn.Linear(256, 128), nn.ReLU(), nn.Dropout(0.2),
    nn.Linear(128, 128), nn.ReLU(), nn.Dropout(0.2),
    nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.2),
    nn.Linear(64, 32), nn.ReLU(), 
    nn.Linear(32, 10))


model3 = model3.to(device)

criterion = nn.CrossEntropyLoss()

optimizer_conv = optim.Adam(model3.parameters(), lr=0.001)

exp_lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer_conv, T_max=100)

model3

accuracy3 = {'train': [], 'val': []}
loss3 = {'train': [], 'val': []}
num_epochs = 30
model3 = train_model(model3, criterion, optimizer_conv, exp_lr_scheduler, num_epochs, accuracy3, loss3)

fig = plt.figure(figsize=(9,5))
plt.plot(accuracy3['train'], label='train_acc')
plt.plot(accuracy3['val'], label='val_acc')
plt.xlabel('Number of Epochs')
plt.ylabel('Accuracy')
plt.legend()

fig = plt.figure(figsize=(9,5))
plt.plot(loss3['train'], label='train_loss')
plt.plot(loss3['val'], label='val_loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

_, acc_train3 = evaluate(model3, 'train')
_, acc_val3 = evaluate(model3, 'val')
_, acc_test3 = evaluate(model3, 'test')

print('Training  Accuracy:   %.3f' % acc_train3)
print('Validation Accuracy:  %.3f' % acc_val3)
print('Testing Accuracy:     %.3f' % acc_test3)

fig = plt.figure(figsize=(9,5))
plt.plot(accuracy1['train'], 'b', label='pretrained = false')
plt.plot(acc2['train'][0:30], 'g',label='pretrained with config 1')
plt.plot(accuracy3['train'], 'r',label='pretrained with config 2')

plt.xlabel('Epochs')
plt.ylabel('Training Accuracy')
plt.title('Comparison between 2 configurations after freezing 7 layers')
plt.legend()

fig = plt.figure(figsize=(9,5))
plt.plot(loss1['train'], 'b', label='pretrained = false')
plt.plot(loss2['train'][0:30], 'g',label='pretrained with config 1')
plt.plot(loss3['train'], 'r',label='pretrained with config 2')
plt.xlabel('Epochs')
plt.ylabel('Training Loss')
plt.title('Comparison between 2 configurations after freezing 7 layers')
plt.legend()

"""PART B"""

import torch
from torch import optim, nn
import torchvision
from torchvision import datasets, models, transforms
import PIL
import numpy as np
import torch.nn.functional as F

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

import matplotlib as mpl
mpl.rcParams['axes.grid'] = False
mpl.rcParams['image.interpolation'] = 'nearest'
mpl.rcParams['figure.figsize'] = 7, 9

def show_dataset(dataset, n=6):
  img = np.vstack((np.hstack((np.asarray(trainset[i][0]) for _ in range(6)))
                   for i in range(4)))
  plt.imshow(img)
  plt.axis('off')

trainset = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True)
show_dataset(trainset)

transforms = torchvision.transforms.Compose([
    # torchvision.transforms.Resize((224,224)),
    # torchvision.transforms.RandomResizedCrop(24),
    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),
    torchvision.transforms.RandomHorizontalFlip(),
    #torchvision.transforms.RandomRotation(20, resample=PIL.Image.BILINEAR)
    torchvision.transforms.RandomRotation(20)
])

trainset = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True, transform=transforms)
show_dataset(trainset)

transforms = torchvision.transforms.Compose([
    torchvision.transforms.RandomCrop(32, padding=4),
    torchvision.transforms.Resize((224,224)),
    torchvision.transforms.RandomResizedCrop(224),
    torchvision.transforms.CenterCrop(224),
    # torchvision.transforms.ColorJitter(hue=.05, saturation=.05),
    # torchvision.transforms.RandomHorizontalFlip(),
    # torchvision.transforms.RandomRotation(20, resample=PIL.Image.BILINEAR)
])

trainset = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True, transform=transforms)
show_dataset(trainset)

pip install torchtoolbox

from torchvision import transforms
from torchtoolbox.transform import Cutout

transforms = torchvision.transforms.Compose([
    # torchvision.transforms.RandomResizedCrop(224),
    Cutout(),
    torchvision.transforms.RandomHorizontalFlip(),
    # torchvision.transforms.ColorJitter(0.4, 0.4, 0.4),
])

trainset = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True, transform=transforms)
show_dataset(trainset)

!pip install git+https://github.com/aleju/imgaug
from imgaug import augmenters as iaa
import imgaug as ia

class ImgAugTransform:
  def __init__(self):
    self.aug = iaa.Sequential([
        iaa.Scale((224, 224)),
        iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0, 3.0))),
        # iaa.Fliplr(0.5),
        iaa.Affine(rotate=(-20, 20), mode='symmetric'),
        iaa.Sometimes(0.25,
                      iaa.OneOf([iaa.Dropout(p=(0, 0.1)),
                                 iaa.CoarseDropout(0.1, size_percent=0.5)])),
        iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)
    ])
      
  def __call__(self, img):
    img = np.array(img)
    return self.aug.augment_image(img)

transforms = ImgAugTransform()

trainset = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True, transform=transforms)
show_dataset(trainset)

class ImgAugTransform:
  def __init__(self):
    self.aug = iaa.Sequential([
        iaa.Scale((224, 224)),
        iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0, 3.0))),
        iaa.Sometimes(0.5,iaa.Cutout()),
        # iaa.Fliplr(0.5),
        # iaa.Affine(rotate=(-20, 20), mode='symmetric'),
        # iaa.Sometimes(0.25,
        #               iaa.OneOf([iaa.Dropout(p=(0, 0.1)),
        #                          iaa.CoarseDropout(0.1, size_percent=0.5)])),
        # iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)
    ])
      
  def __call__(self, img):
    img = np.array(img)
    return self.aug.augment_image(img)

transforms = ImgAugTransform()

trainset = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True, transform=transforms)
show_dataset(trainset)

class ImgAugTransform:
  def __init__(self):
    self.aug = iaa.Sequential([
        iaa.Scale((224, 224)),
        iaa.Sometimes(0.25,iaa.SaltAndPepper(0.02)),
        iaa.Fliplr(0.5),
        # iaa.Affine(rotate=(-20, 20), mode='symmetric'),
        # iaa.Sometimes(0.25,
        #               iaa.OneOf([iaa.Dropout(p=(0, 0.1)),
        #                          iaa.CoarseDropout(0.1, size_percent=0.5)])),
        # iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)
    ])
      
  def __call__(self, img):
    img = np.array(img)
    return self.aug.augment_image(img)

transforms = ImgAugTransform()

trainset = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True, transform=transforms)
show_dataset(trainset)

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torch.backends.cudnn as cudnn
import torchvision
import torchvision.transforms as transforms
import PIL
import numpy as np
import os
import argparse
import matplotlib.pyplot as plt

class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, in_planes, planes, stride=1, dropRate=0.0):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(
            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,
                               stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)
        self.droprate = dropRate
        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != self.expansion*planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, self.expansion*planes,
                          kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(self.expansion*planes)
            )

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        out = F.relu(out)
        return out

class ResNet(nn.Module):
    def __init__(self, block, num_blocks, num_classes=10, dropRate=0.0):
        super(ResNet, self).__init__()
        self.in_planes = 64

        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,
                               stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.layer1 = self._make_layer(block, 64, num_blocks[0], dropRate, stride=1)
        self.layer2 = self._make_layer(block, 128, num_blocks[1], dropRate, stride=2)
        self.layer3 = self._make_layer(block, 256, num_blocks[2], dropRate, stride=2)
        self.layer4 = self._make_layer(block, 512, num_blocks[3], dropRate, stride=2)
        self.linear = nn.Linear(512*block.expansion, num_classes)

    def _make_layer(self, block, planes, num_blocks, dropRate, stride):
        strides = [stride] + [1]*(num_blocks-1)
        layers = []
        for stride in strides:
            layers.append(block(self.in_planes, planes, stride, dropRate))
            self.in_planes = planes * block.expansion
        return nn.Sequential(*layers)

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = F.avg_pool2d(out, 4)
        out = out.view(out.size(0), -1)
        out = self.linear(out)
        return out

def ResNet18(rate):
    return ResNet(BasicBlock, [2, 2, 2, 2], dropRate = rate)

class ImgAugTransform:
  def __init__(self):
    self.aug = iaa.Sequential([
        iaa.Scale((224, 224)),
        iaa.Sometimes(0.1,iaa.SaltAndPepper(0.02)),
        iaa.Sometimes(0.1, iaa.GaussianBlur(sigma=(0, 3.0))),
        iaa.Sometimes(0.1,iaa.Cutout()),

    ])
      
  def __call__(self, img):
    img = np.array(img)
    return self.aug.augment_image(img)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
best_acc = 0  # best test accuracy
start_epoch = 0  # start from epoch 0 or last checkpoint epoch

# Data
print('==> Preparing data..')
transform_train = transforms.Compose([                                  
    # transforms.RandomCrop(32, padding=4),
    transforms.ColorJitter(hue=0.05, saturation=0.05),
    transforms.RandomHorizontalFlip(),
    # transforms.CenterCrop(10),
    transforms.RandomApply(torch.nn.ModuleList([transforms.GaussianBlur(3, sigma=(0.1, 1.0)),]), p=0.1),
    # transforms.GaussianBlur(3, sigma=(0.1, 1.0)),
    transforms.RandomRotation(20),
    # ImgAugTransform(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])
transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])

trainset = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True, transform=transform_train)
trainset, val_set = torch.utils.data.random_split(trainset, [5000, 45000])

trainloader = torch.utils.data.DataLoader(
    trainset, batch_size=128, shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(
    root='./data', train=False, download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(
    testset, batch_size=100, shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck')

def train(epoch):
    # print('\nEpoch: %d' % epoch)
    net.train()
    train_loss = 0
    correct = 0
    total = 0
    for batch_idx, (inputs, targets) in enumerate(trainloader):
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()

    print('Train Epoch: {} [{}/{} ({:.0f}%)] \tAcc: {:.3f}% ({}/{}) \tLoss: {:.6f}'.format(
              epoch, batch_idx * len(inputs), len(trainloader.dataset), 100. * batch_idx / len(trainloader), 100.*correct/total, correct, total, train_loss/(batch_idx+1)))
    return 100.*correct/total, train_loss/(batch_idx+1)

def test(epoch):
    global best_acc
    net.eval()
    test_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for batch_idx, (inputs, targets) in enumerate(testloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            loss = criterion(outputs, targets)

            test_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

        print(
            '\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
            test_loss/(batch_idx+1), correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))

    # Save checkpoint.
    acc = 100.*correct/total
    if acc > best_acc:
        # print('Saving..')
        state = {
            'net': net.state_dict(),
            'acc': acc,
            'epoch': epoch,
        }
        # if not os.path.isdir('checkpoint'):
        #     os.mkdir('checkpoint')
        # torch.save(state, './checkpoint/ckpt.pth')
        best_acc = acc
    return acc, test_loss/(batch_idx+1)

print('==> Building model..')
net = ResNet18(0.0)
net = net.to(device)
if device == 'cuda':
    net = torch.nn.DataParallel(net)
    cudnn.benchmark = True

lr = 0.1
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr,
                      momentum=0.9, weight_decay=5e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)
train_acc = []
test_acc = []
train_loss = []
test_loss = []
for epoch in range(0, 81):
    
    acc, loss = train(epoch)
    if epoch%10==0:
      train_acc.append(acc)
      train_loss.append(loss)
    acc, loss = test(epoch)
    if epoch%10==0:
      test_acc.append(acc)
      test_loss.append(loss)
    scheduler.step()

from matplotlib.legend_handler import HandlerLine2D

epochs = np.linspace(0, 80, 9, endpoint=True)
plt.figure(figsize=(6, 7))
line1, = plt.plot(epochs, train_acc, 'b', label='Train Acc')
line2, = plt.plot(epochs, test_acc, 'r', label='Test Acc')
# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
plt.legend()
plt.ylabel('Accuracy')
# plt.xlabel('Epochs')
plt.title('CNN_ResNet18')
plt.show()

from matplotlib.legend_handler import HandlerLine2D
plt.figure(figsize=(6, 7))
epochs = np.linspace(0, 80, 9, endpoint=True)
line1, = plt.plot(epochs, train_loss, 'b', label='Train Loss')
line2, = plt.plot(epochs, test_loss, 'r', label='Test Loss')
# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
plt.legend()
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.title('ResNet18 with data augmentation')
plt.show()

"""Dropout"""

drop_rate = np.linspace(0, 0.5, 6, endpoint=True)
train_acc = []
test_acc = []
train_loss = []
test_loss = []
for i in drop_rate:
  print(i)
  # Model
  print('==> Building model..')
  net = ResNet18(i)
  net = net.to(device)
  if device == 'cuda':
      net = torch.nn.DataParallel(net)
      cudnn.benchmark = True
  epochs = 75
  lr = 0.1
  criterion = nn.CrossEntropyLoss()
  optimizer = optim.SGD(net.parameters(), lr,
                        momentum=0.9, weight_decay=5e-4)
  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)
  for epoch in range(0, epochs):
    
    acc, loss = train(epoch)
    if epoch==epochs-1:
      train_acc.append(acc)
      train_loss.append(loss)
    acc, loss = test(epoch)
    if epoch==epochs-1:
      test_acc.append(acc)
      test_loss.append(loss)
    scheduler.step()

from matplotlib.legend_handler import HandlerLine2D
fig = plt.figure(figsize=(6,5))
line1, = plt.plot(drop_rate, train_acc, 'b', label='Train Accuracy')
line2, = plt.plot(drop_rate, test_acc, 'r', label='Test Accuracy')
# line3, = plt.plot(drop_rate, val_acc, 'g', label='Val Accuracy')
# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})

plt.legend()
plt.ylabel('Accuracy')
plt.xlabel('Droprate')
plt.title('Varying droprate')
plt.show()

from matplotlib.legend_handler import HandlerLine2D
fig = plt.figure(figsize=(6,5))
line1, = plt.plot(drop_rate, train_loss, 'b', label='Train Accuracy')
line2, = plt.plot(drop_rate, test_loss, 'r', label='Test Accuracy')
# line3, = plt.plot(drop_rate, val_acc, 'g', label='Val Accuracy')
# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})

plt.legend()
plt.ylabel('Loss')
plt.xlabel('Droprate')
plt.title('Varying droprate')
plt.show()

"""partc"""

from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D
from keras.layers import AveragePooling2D, MaxPooling2D, Dropout
from keras.models import Sequential,Model
from keras.optimizers import SGD
from keras.callbacks import ModelCheckpoint,LearningRateScheduler
import keras
from keras import backend as K
import tensorflow as tf

new_input = Input(shape=(32, 32, 3))


model = tf.keras.applications.ResNet50(
    include_top=False,
    weights='imagenet',
    input_tensor=new_input,
    input_shape=None,
    pooling=None,
    classes=10,
    # **kwargs
)

flatten = Flatten()
new_layer2 = Dense(10, activation='softmax', name='my_dense_2')
inp = model.input
out = new_layer2(flatten(model.output))

model = Model(inp, out)
model.summary()
# model.add(layers.Dense(10))
# adding a linear layer of 10 inputs

print(model)
from keras.datasets import cifar10
from keras.utils import to_categorical
# load dataset
(trainX, trainY), (testX, testY) = cifar10.load_data()
# convert from integers to floats
trainX1 = trainX.astype('float32')
testX1 = testX.astype('float32')
# normalize to range 0-1
trainX1 = trainX1 / 255.0
testX1 = testX1 / 255.0
trainY1 = to_categorical(trainY)
testY1 = to_categorical(testY)

model.summary()

model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')
history = model.fit(trainX1, trainY1, 
                    validation_data=(testX1, testY1),
                    epochs=5, 
                    batch_size=32,
                    verbose=1, 
                    )

"""PART C"""

from keras.models import Model
# print(model.layers)
layer_outputs = [layer.output for layer in model.layers]
activation_model = Model(inputs=model.input, outputs=layer_outputs)
# print(trainX1[10].shape)
activations = activation_model.predict(trainX1[5].reshape(1,32,32,3))
 
def display_activation(activations, col_size, row_size, act_index): 
    activation = activations[act_index]
    activation_index=0
    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))
    for row in range(0,row_size):
        for col in range(0,col_size):
            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')
            activation_index += 1

import matplotlib.pyplot as plt
plt.imshow(trainX1[5][:,:,:]);
print(activations[2].shape)
# print(len(activations))

display_activation(activations, 8, 8, 2)